{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-07T10:36:35.338205Z","iopub.execute_input":"2023-04-07T10:36:35.339140Z","iopub.status.idle":"2023-04-07T10:36:35.349530Z","shell.execute_reply.started":"2023-04-07T10:36:35.339103Z","shell.execute_reply":"2023-04-07T10:36:35.348471Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:35.770104Z","iopub.execute_input":"2023-04-07T10:36:35.771287Z","iopub.status.idle":"2023-04-07T10:36:36.976000Z","shell.execute_reply.started":"2023-04-07T10:36:35.771247Z","shell.execute_reply":"2023-04-07T10:36:36.974962Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":" device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:36.979240Z","iopub.execute_input":"2023-04-07T10:36:36.980381Z","iopub.status.idle":"2023-04-07T10:36:37.046511Z","shell.execute_reply.started":"2023-04-07T10:36:36.980341Z","shell.execute_reply":"2023-04-07T10:36:37.045391Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class DNN(nn.Module):\n    def __init__(self, input_shape, num_classes):\n        super(DNN, self).__init__()\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        \n        #defining layers\n        self.linear1 = nn.Linear(in_features = self.input_shape, out_features = 392)\n        self.linear2 = nn.Linear(in_features= 392, out_features = self.num_classes)\n        \n        #defining activation function\n        self.relu = nn.ReLU()\n        \n    def forward(self, X):\n        X = self.linear1(X)\n        X = self.relu(X)\n        X = self.linear2(X)\n        return X\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:37.048291Z","iopub.execute_input":"2023-04-07T10:36:37.048717Z","iopub.status.idle":"2023-04-07T10:36:37.057919Z","shell.execute_reply.started":"2023-04-07T10:36:37.048679Z","shell.execute_reply":"2023-04-07T10:36:37.057037Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperparameters","metadata":{}},{"cell_type":"code","source":"input_shape = 784\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 10000\nnum_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:40.741936Z","iopub.execute_input":"2023-04-07T10:36:40.742297Z","iopub.status.idle":"2023-04-07T10:36:40.747995Z","shell.execute_reply.started":"2023-04-07T10:36:40.742265Z","shell.execute_reply":"2023-04-07T10:36:40.746765Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Loading Data (Can also load from digit recognizer but have to do some preprocessing)","metadata":{}},{"cell_type":"code","source":"#Downloading Data Set of MNIST\ntrain_dataset = datasets.MNIST(root=\"/kaggle/working/\", train = True, transform = transforms.ToTensor(), download = True)\ntest_dataset = datasets.MNIST(root=\"/kaggle/working/\", train = False, transform = transforms.ToTensor(), download = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:45.297684Z","iopub.execute_input":"2023-04-07T10:36:45.298384Z","iopub.status.idle":"2023-04-07T10:36:46.266898Z","shell.execute_reply.started":"2023-04-07T10:36:45.298345Z","shell.execute_reply":"2023-04-07T10:36:46.265847Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3d0a41ea91b45c5a148e88aed37b1d4"}},"metadata":{}},{"name":"stdout","text":"Extracting /kaggle/working/MNIST/raw/train-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f03b0a7811e24abb83182629c0a5836a"}},"metadata":{}},{"name":"stdout","text":"Extracting /kaggle/working/MNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1d686a99cdf409c9143931862250e25"}},"metadata":{}},{"name":"stdout","text":"Extracting /kaggle/working/MNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d77e3f6c96754e86ae8b76cb56b7a038"}},"metadata":{}},{"name":"stdout","text":"Extracting /kaggle/working/MNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Creating Generator a.k.a Dataloader\ntrain_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\ntest_dataloader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:50.933421Z","iopub.execute_input":"2023-04-07T10:36:50.933780Z","iopub.status.idle":"2023-04-07T10:36:50.939376Z","shell.execute_reply.started":"2023-04-07T10:36:50.933745Z","shell.execute_reply":"2023-04-07T10:36:50.938186Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Creating and Instance of model","metadata":{}},{"cell_type":"code","source":"model = DNN(input_shape = input_shape, num_classes = num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:54.293297Z","iopub.execute_input":"2023-04-07T10:36:54.294225Z","iopub.status.idle":"2023-04-07T10:36:54.313392Z","shell.execute_reply.started":"2023-04-07T10:36:54.294174Z","shell.execute_reply":"2023-04-07T10:36:54.312485Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\nmodel = model.to(device)\nfor epoch in tqdm(range(num_epochs)):\n    epoch_loss = 0\n    for batch in train_dataloader:\n        batch[0] = batch[0].view(batch[0].shape[0], -1).to(device)\n        batch[1] = batch[1].to(device)\n        \n        inference = model.forward(batch[0])\n        \n        loss = criterion(inference, batch[1])\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n        epoch_loss += loss\n    if epoch%10 == 0:\n        print(f\"epoch:- {epoch.__str__().zfill(3)} loss :- {epoch_loss/len(train_dataloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:36:56.637504Z","iopub.execute_input":"2023-04-07T10:36:56.637870Z","iopub.status.idle":"2023-04-07T10:46:24.281403Z","shell.execute_reply.started":"2023-04-07T10:36:56.637837Z","shell.execute_reply":"2023-04-07T10:46:24.280321Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec1163e15b8a4f2ea0e8d8a0b4cb0d2d"}},"metadata":{}},{"name":"stdout","text":"epoch:- 000 loss :- 2.018967390060425\nepoch:- 010 loss :- 0.2893773913383484\nepoch:- 020 loss :- 0.20374926924705505\nepoch:- 030 loss :- 0.15015795826911926\nepoch:- 040 loss :- 0.11508109420537949\nepoch:- 050 loss :- 0.08999183028936386\nepoch:- 060 loss :- 0.07169702649116516\nepoch:- 070 loss :- 0.05835160240530968\nepoch:- 080 loss :- 0.04758518189191818\nepoch:- 090 loss :- 0.03912240266799927\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    model.eval()\n    with torch.no_grad():\n        num_correct = 0\n        total_example = 0\n        for batch in dataloader:\n            batch[0] = batch[0].view(batch[0].shape[0], -1).to(device)\n            batch[1] = batch[1].to(device)\n\n            inference = model.forward(batch[0])\n            #output of max is max_value for each example with index location of the max in the last 10 neuron (y_pred) so no need of using softmax activation\n            _, y_pred = torch.max(inference, dim = 1)\n            num_correct += (y_pred == batch[1]).sum()\n            total_example += inference.shape[0]\n            \n    print(f\"Accuracy:- {num_correct/total_example}\")\n            ","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:58:57.673870Z","iopub.execute_input":"2023-04-07T10:58:57.674549Z","iopub.status.idle":"2023-04-07T10:58:57.681779Z","shell.execute_reply.started":"2023-04-07T10:58:57.674514Z","shell.execute_reply":"2023-04-07T10:58:57.680570Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Evaluation on Test Dataset\nevaluate(model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:01:11.127734Z","iopub.execute_input":"2023-04-07T11:01:11.128335Z","iopub.status.idle":"2023-04-07T11:01:12.188522Z","shell.execute_reply.started":"2023-04-07T11:01:11.128299Z","shell.execute_reply":"2023-04-07T11:01:12.187437Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Accuracy:- 0.9757999777793884\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation on Train Dataset\nevaluate(model, train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:01:22.918956Z","iopub.execute_input":"2023-04-07T11:01:22.919329Z","iopub.status.idle":"2023-04-07T11:01:28.326025Z","shell.execute_reply.started":"2023-04-07T11:01:22.919297Z","shell.execute_reply":"2023-04-07T11:01:28.324915Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Accuracy:- 0.992900013923645\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}