{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-09T11:18:40.166106Z","iopub.execute_input":"2023-04-09T11:18:40.167049Z","iopub.status.idle":"2023-04-09T11:18:40.174294Z","shell.execute_reply.started":"2023-04-09T11:18:40.166966Z","shell.execute_reply":"2023-04-09T11:18:40.173055Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:18:41.265114Z","iopub.execute_input":"2023-04-09T11:18:41.265822Z","iopub.status.idle":"2023-04-09T11:18:43.632109Z","shell.execute_reply.started":"2023-04-09T11:18:41.265783Z","shell.execute_reply":"2023-04-09T11:18:43.631061Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":" device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:18:43.635309Z","iopub.execute_input":"2023-04-09T11:18:43.636259Z","iopub.status.idle":"2023-04-09T11:18:43.696373Z","shell.execute_reply.started":"2023-04-09T11:18:43.636217Z","shell.execute_reply":"2023-04-09T11:18:43.695253Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### For understanding how the input output works for RNNs","metadata":{}},{"cell_type":"code","source":"embedding_size = 28\nhidden_size = 1000\nbatch_size = 10000\nsequence_length = 28\nnum_layers = 1\nbidirectional = False\n\nrnn = nn.RNN(\n            input_size = embedding_size,\n            hidden_size = hidden_size,\n            num_layers = num_layers,\n            bidirectional = bidirectional,\n            batch_first = True\n        )","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:18:45.959878Z","iopub.execute_input":"2023-04-09T11:18:45.960773Z","iopub.status.idle":"2023-04-09T11:18:45.997539Z","shell.execute_reply.started":"2023-04-09T11:18:45.960725Z","shell.execute_reply":"2023-04-09T11:18:45.996566Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X = torch.randn((batch_size, sequence_length, embedding_size))\nh_0 = torch.zeros(((int(bidirectional) + 1)*num_layers, batch_size, hidden_size))","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:18:50.500167Z","iopub.execute_input":"2023-04-09T11:18:50.500746Z","iopub.status.idle":"2023-04-09T11:18:50.599764Z","shell.execute_reply.started":"2023-04-09T11:18:50.500711Z","shell.execute_reply":"2023-04-09T11:18:50.598711Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(f\"Input Vector size: - {X.size()}\")\nprint(f\"Initial Hidden State size: - {h_0.size()}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:18:51.689792Z","iopub.execute_input":"2023-04-09T11:18:51.690874Z","iopub.status.idle":"2023-04-09T11:18:51.698426Z","shell.execute_reply.started":"2023-04-09T11:18:51.690833Z","shell.execute_reply":"2023-04-09T11:18:51.697214Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Input Vector size: - torch.Size([10000, 28, 28])\nInitial Hidden State size: - torch.Size([1, 10000, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs, h_n = rnn(X, h_0)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:18:53.079945Z","iopub.execute_input":"2023-04-09T11:18:53.080337Z","iopub.status.idle":"2023-04-09T11:19:00.574858Z","shell.execute_reply.started":"2023-04-09T11:18:53.080304Z","shell.execute_reply":"2023-04-09T11:19:00.573790Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(f\"Output size: - {outputs.size()}\")\nprint(f\"Final Hidden State size: - {h_n.size()}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:19:00.577159Z","iopub.execute_input":"2023-04-09T11:19:00.577543Z","iopub.status.idle":"2023-04-09T11:19:00.583168Z","shell.execute_reply.started":"2023-04-09T11:19:00.577505Z","shell.execute_reply":"2023-04-09T11:19:00.582052Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Output size: - torch.Size([10000, 28, 1000])\nFinal Hidden State size: - torch.Size([1, 10000, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"h_n.squeeze_(0).size()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:19:00.584457Z","iopub.execute_input":"2023-04-09T11:19:00.584959Z","iopub.status.idle":"2023-04-09T11:19:00.604727Z","shell.execute_reply.started":"2023-04-09T11:19:00.584920Z","shell.execute_reply":"2023-04-09T11:19:00.603774Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"torch.Size([10000, 1000])"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Implementing the Architecture using Unidirectional and 1 Layer RNN","metadata":{}},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self,batch_size, embedding_size, hidden_size, num_classes):\n        super(RNN, self).__init__()\n        self.batch_size = batch_size\n        self.embedding_size = embedding_size #aka input_size\n        self.hidden_size = hidden_size\n        self.num_classes = num_classes\n        \n        #defining layers\n        self.rnn = nn.RNN(\n            input_size = self.embedding_size,\n            hidden_size = self.hidden_size,\n            num_layers = 1,\n            batch_first = True\n        )\n        self.linear = nn.Linear(in_features = self.hidden_size,out_features = self.num_classes)\n        \n        #defining activation function\n        self.tanh = nn.Tanh()\n        \n    def forward(self, X):\n        #X.size() = (batch_size = self.batch_size, sequence_length = 28, input_size = 28)\n        _,X = self.rnn(X.squeeze(1))\n        X = self.tanh(X)\n        X = self.linear(X.squeeze(0))\n        return X","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:43:31.387043Z","iopub.execute_input":"2023-04-09T11:43:31.388155Z","iopub.status.idle":"2023-04-09T11:43:31.396527Z","shell.execute_reply.started":"2023-04-09T11:43:31.388098Z","shell.execute_reply":"2023-04-09T11:43:31.395335Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperparameters","metadata":{}},{"cell_type":"code","source":"in_channels = 1\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 10000\nnum_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:43:32.329147Z","iopub.execute_input":"2023-04-09T11:43:32.329596Z","iopub.status.idle":"2023-04-09T11:43:32.336998Z","shell.execute_reply.started":"2023-04-09T11:43:32.329560Z","shell.execute_reply":"2023-04-09T11:43:32.335784Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"#### Loading Data (Can also load from digit recognizer but have to do some preprocessing)","metadata":{}},{"cell_type":"code","source":"#Downloading Data Set of MNIST\ntrain_dataset = datasets.MNIST(root=\"/kaggle/working/\", train = True, transform = transforms.ToTensor(), download = True)\ntest_dataset = datasets.MNIST(root=\"/kaggle/working/\", train = False, transform = transforms.ToTensor(), download = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:43:33.434035Z","iopub.execute_input":"2023-04-09T11:43:33.434409Z","iopub.status.idle":"2023-04-09T11:43:33.513916Z","shell.execute_reply.started":"2023-04-09T11:43:33.434377Z","shell.execute_reply":"2023-04-09T11:43:33.512921Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#Creating Generator a.k.a Dataloader\ntrain_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\ntest_dataloader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:43:34.308514Z","iopub.execute_input":"2023-04-09T11:43:34.309168Z","iopub.status.idle":"2023-04-09T11:43:34.317346Z","shell.execute_reply.started":"2023-04-09T11:43:34.309128Z","shell.execute_reply":"2023-04-09T11:43:34.316386Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"#### Creating and Instance of model","metadata":{}},{"cell_type":"code","source":"model = RNN(batch_size = batch_size, embedding_size = 28, hidden_size = 1000, num_classes =10)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:43:35.267060Z","iopub.execute_input":"2023-04-09T11:43:35.267426Z","iopub.status.idle":"2023-04-09T11:43:35.285021Z","shell.execute_reply.started":"2023-04-09T11:43:35.267394Z","shell.execute_reply":"2023-04-09T11:43:35.284042Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\nmodel = model.to(device)\nfor epoch in tqdm(range(num_epochs + 1)):\n    epoch_loss = 0\n    for batch in train_dataloader:\n        batch[0] = batch[0].to(device)\n        batch[1] = batch[1].to(device)\n        inference = model.forward(batch[0])\n        \n        loss = criterion(inference, batch[1])\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n        epoch_loss += loss.item()\n    if epoch%10 == 0:\n        print(f\"epoch:- {epoch.__str__().zfill(3)} loss :- {epoch_loss/len(train_dataloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:43:35.846899Z","iopub.execute_input":"2023-04-09T11:43:35.847600Z","iopub.status.idle":"2023-04-09T11:56:16.367976Z","shell.execute_reply.started":"2023-04-09T11:43:35.847563Z","shell.execute_reply":"2023-04-09T11:56:16.366854Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/101 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c156b4fd8f040859d1aba46270decc5"}},"metadata":{}},{"name":"stdout","text":"epoch:- 000 loss :- 2.4832040270169577\nepoch:- 010 loss :- 2.3023281494776406\nepoch:- 020 loss :- 2.3016357819239297\nepoch:- 040 loss :- 1.618962029616038\nepoch:- 050 loss :- 1.2499530911445618\nepoch:- 060 loss :- 0.911984254916509\nepoch:- 070 loss :- 0.6202460825443268\nepoch:- 080 loss :- 0.6948716839154562\nepoch:- 090 loss :- 0.32425135374069214\nepoch:- 100 loss :- 0.24893589317798615\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    model.eval()\n    with torch.no_grad():\n        num_correct = 0\n        total_example = 0\n        for batch in dataloader:\n            batch[0] = batch[0].to(device)\n            batch[1] = batch[1].to(device)\n\n            inference = model.forward(batch[0])\n            #output of max is max_value for each example with index location of the max in the last 10 neuron (y_pred) so no need of using softmax activation\n            _, y_pred = torch.max(inference, dim = 1)\n            num_correct += (y_pred == batch[1]).sum()\n            total_example += inference.shape[0]\n            \n    print(f\"Accuracy:- {num_correct/total_example}\")\n            ","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:56:23.294797Z","iopub.execute_input":"2023-04-09T11:56:23.295507Z","iopub.status.idle":"2023-04-09T11:56:23.304948Z","shell.execute_reply.started":"2023-04-09T11:56:23.295461Z","shell.execute_reply":"2023-04-09T11:56:23.303290Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Evaluation on Test Dataset\nevaluate(model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:56:23.306080Z","iopub.execute_input":"2023-04-09T11:56:23.308219Z","iopub.status.idle":"2023-04-09T11:56:24.296692Z","shell.execute_reply.started":"2023-04-09T11:56:23.308189Z","shell.execute_reply":"2023-04-09T11:56:24.295549Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Accuracy:- 0.9299999475479126\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation on Train Dataset\nevaluate(model, train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T11:56:24.298346Z","iopub.execute_input":"2023-04-09T11:56:24.298722Z","iopub.status.idle":"2023-04-09T11:56:30.135205Z","shell.execute_reply.started":"2023-04-09T11:56:24.298685Z","shell.execute_reply":"2023-04-09T11:56:30.134056Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Accuracy:- 0.9287833571434021\n","output_type":"stream"}]}]}