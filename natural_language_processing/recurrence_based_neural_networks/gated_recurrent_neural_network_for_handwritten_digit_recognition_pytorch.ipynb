{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-09T13:16:10.984904Z","iopub.execute_input":"2023-04-09T13:16:10.985408Z","iopub.status.idle":"2023-04-09T13:16:10.993903Z","shell.execute_reply.started":"2023-04-09T13:16:10.985361Z","shell.execute_reply":"2023-04-09T13:16:10.992836Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:16:11.567576Z","iopub.execute_input":"2023-04-09T13:16:11.568195Z","iopub.status.idle":"2023-04-09T13:16:11.574487Z","shell.execute_reply.started":"2023-04-09T13:16:11.568143Z","shell.execute_reply":"2023-04-09T13:16:11.573276Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":" device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:16:11.860589Z","iopub.execute_input":"2023-04-09T13:16:11.861385Z","iopub.status.idle":"2023-04-09T13:16:11.869451Z","shell.execute_reply.started":"2023-04-09T13:16:11.861343Z","shell.execute_reply":"2023-04-09T13:16:11.868394Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### For understanding how the input output works for LSTMs","metadata":{}},{"cell_type":"code","source":"embedding_size = 28\nhidden_size = 1000\nbatch_size = 100\nsequence_length = 28\nnum_layers = 1\nbidirectional = False\n\ngru = nn.GRU(\n            input_size = embedding_size,\n            hidden_size = hidden_size,\n            num_layers = num_layers,\n            bidirectional = bidirectional,\n            batch_first = True\n        )","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:56:26.912110Z","iopub.execute_input":"2023-04-09T13:56:26.913204Z","iopub.status.idle":"2023-04-09T13:56:26.943065Z","shell.execute_reply.started":"2023-04-09T13:56:26.913154Z","shell.execute_reply":"2023-04-09T13:56:26.942161Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"X = torch.randn((batch_size, sequence_length, embedding_size))\nh_0 = torch.zeros(((int(bidirectional) + 1)*num_layers, batch_size, hidden_size))","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:56:27.391396Z","iopub.execute_input":"2023-04-09T13:56:27.391767Z","iopub.status.idle":"2023-04-09T13:56:27.400594Z","shell.execute_reply.started":"2023-04-09T13:56:27.391731Z","shell.execute_reply":"2023-04-09T13:56:27.399431Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(f\"Input Vector size: - {X.size()}\")\nprint(f\"Initial Hidden State size: - {h_0.size()}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:56:27.857555Z","iopub.execute_input":"2023-04-09T13:56:27.858637Z","iopub.status.idle":"2023-04-09T13:56:27.866206Z","shell.execute_reply.started":"2023-04-09T13:56:27.858581Z","shell.execute_reply":"2023-04-09T13:56:27.864872Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Input Vector size: - torch.Size([100, 28, 28])\nInitial Hidden State size: - torch.Size([1, 100, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs, h_n = gru(X, h_0)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:56:28.745488Z","iopub.execute_input":"2023-04-09T13:56:28.746479Z","iopub.status.idle":"2023-04-09T13:56:28.998750Z","shell.execute_reply.started":"2023-04-09T13:56:28.746431Z","shell.execute_reply":"2023-04-09T13:56:28.997683Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(f\"Output size: - {outputs.size()}\")\nprint(f\"Final Hidden State size: - {h_n.size()}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:56:29.497294Z","iopub.execute_input":"2023-04-09T13:56:29.498469Z","iopub.status.idle":"2023-04-09T13:56:29.504712Z","shell.execute_reply.started":"2023-04-09T13:56:29.498419Z","shell.execute_reply":"2023-04-09T13:56:29.503617Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Output size: - torch.Size([100, 28, 1000])\nFinal Hidden State size: - torch.Size([1, 100, 1000])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Implementing the Architecture using Unidirectional and 1 Layer RNN","metadata":{}},{"cell_type":"code","source":"class GRU(nn.Module):\n    def __init__(self,batch_size, embedding_size, hidden_size, num_classes):\n        super(GRU, self).__init__()\n        self.batch_size = batch_size\n        self.embedding_size = embedding_size #aka input_size\n        self.hidden_size = hidden_size\n        self.num_classes = num_classes\n        \n        #defining layers\n        self.gru = nn.GRU(\n            input_size = self.embedding_size,\n            hidden_size = self.hidden_size,\n            num_layers = 1,\n            batch_first = True\n        )\n        self.linear = nn.Linear(in_features = self.hidden_size,out_features = self.num_classes)\n        \n        #defining activation function\n        self.tanh = nn.Tanh()\n        \n    def forward(self, X):\n        #X.size() = (batch_size = self.batch_size, sequence_length = 28, input_size = 28)\n        _,X  = self.gru(X.squeeze(1))\n        X = self.tanh(X)\n        X = self.linear(X.squeeze(0))\n        return X","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:58:12.781309Z","iopub.execute_input":"2023-04-09T13:58:12.781674Z","iopub.status.idle":"2023-04-09T13:58:12.790818Z","shell.execute_reply.started":"2023-04-09T13:58:12.781639Z","shell.execute_reply":"2023-04-09T13:58:12.789795Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperparameters","metadata":{}},{"cell_type":"code","source":"in_channels = 1\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 5000\nnum_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:58:13.911981Z","iopub.execute_input":"2023-04-09T13:58:13.912617Z","iopub.status.idle":"2023-04-09T13:58:13.918019Z","shell.execute_reply.started":"2023-04-09T13:58:13.912577Z","shell.execute_reply":"2023-04-09T13:58:13.916917Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"#### Loading Data (Can also load from digit recognizer but have to do some preprocessing)","metadata":{}},{"cell_type":"code","source":"#Downloading Data Set of MNIST\ntrain_dataset = datasets.MNIST(root=\"/kaggle/working/\", train = True, transform = transforms.ToTensor(), download = True)\ntest_dataset = datasets.MNIST(root=\"/kaggle/working/\", train = False, transform = transforms.ToTensor(), download = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:58:13.952915Z","iopub.execute_input":"2023-04-09T13:58:13.953226Z","iopub.status.idle":"2023-04-09T13:58:14.028870Z","shell.execute_reply.started":"2023-04-09T13:58:13.953196Z","shell.execute_reply":"2023-04-09T13:58:14.027853Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#Creating Generator a.k.a Dataloader\ntrain_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\ntest_dataloader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:58:14.212693Z","iopub.execute_input":"2023-04-09T13:58:14.213816Z","iopub.status.idle":"2023-04-09T13:58:14.223770Z","shell.execute_reply.started":"2023-04-09T13:58:14.213773Z","shell.execute_reply":"2023-04-09T13:58:14.222682Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"#### Creating and Instance of model","metadata":{}},{"cell_type":"code","source":"model = GRU(batch_size = batch_size, embedding_size = 28, hidden_size = 1000, num_classes =10)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:58:15.452291Z","iopub.execute_input":"2023-04-09T13:58:15.452655Z","iopub.status.idle":"2023-04-09T13:58:15.483237Z","shell.execute_reply.started":"2023-04-09T13:58:15.452622Z","shell.execute_reply":"2023-04-09T13:58:15.482276Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\nmodel = model.to(device)\nfor epoch in tqdm(range(num_epochs + 1)):\n    epoch_loss = 0\n    for batch in train_dataloader:\n        batch[0] = batch[0].to(device)\n        batch[1] = batch[1].to(device)\n        inference = model.forward(batch[0])\n        \n        loss = criterion(inference, batch[1])\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n        epoch_loss += loss.item()\n    if epoch%10 == 0:\n        print(f\"epoch:- {epoch.__str__().zfill(3)} loss :- {epoch_loss/len(train_dataloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T13:58:16.057660Z","iopub.execute_input":"2023-04-09T13:58:16.058650Z","iopub.status.idle":"2023-04-09T14:16:12.855260Z","shell.execute_reply.started":"2023-04-09T13:58:16.058595Z","shell.execute_reply":"2023-04-09T14:16:12.854186Z"},"trusted":true},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/101 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7a0102f76124716bcb916aa81a5b90a"}},"metadata":{}},{"name":"stdout","text":"epoch:- 000 loss :- 2.0489796797434487\nepoch:- 010 loss :- 0.2972995936870575\nepoch:- 020 loss :- 0.09976431416968505\nepoch:- 030 loss :- 0.04836665311207374\nepoch:- 040 loss :- 0.028022811903307836\nepoch:- 050 loss :- 0.017457003006711602\nepoch:- 060 loss :- 0.00904205619978408\nepoch:- 070 loss :- 0.009698205705111226\nepoch:- 080 loss :- 0.004207541700452566\nepoch:- 090 loss :- 0.0008741036047770953\nepoch:- 100 loss :- 0.00468514939226831\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    model.eval()\n    with torch.no_grad():\n        num_correct = 0\n        total_example = 0\n        for batch in dataloader:\n            batch[0] = batch[0].to(device)\n            batch[1] = batch[1].to(device)\n\n            inference = model.forward(batch[0])\n            #output of max is max_value for each example with index location of the max in the last 10 neuron (y_pred) so no need of using softmax activation\n            _, y_pred = torch.max(inference, dim = 1)\n            num_correct += (y_pred == batch[1]).sum()\n            total_example += inference.shape[0]\n            \n    print(f\"Accuracy:- {num_correct/total_example}\")\n            ","metadata":{"execution":{"iopub.status.busy":"2023-04-09T14:16:19.110886Z","iopub.execute_input":"2023-04-09T14:16:19.111383Z","iopub.status.idle":"2023-04-09T14:16:19.118668Z","shell.execute_reply.started":"2023-04-09T14:16:19.111340Z","shell.execute_reply":"2023-04-09T14:16:19.117396Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Evaluation on Test Dataset\nevaluate(model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T14:16:19.968500Z","iopub.execute_input":"2023-04-09T14:16:19.969121Z","iopub.status.idle":"2023-04-09T14:16:20.993309Z","shell.execute_reply.started":"2023-04-09T14:16:19.969079Z","shell.execute_reply":"2023-04-09T14:16:20.992173Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Accuracy:- 0.9858999848365784\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation on Train Dataset\nevaluate(model, train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T14:16:22.815441Z","iopub.execute_input":"2023-04-09T14:16:22.816379Z","iopub.status.idle":"2023-04-09T14:16:28.425059Z","shell.execute_reply.started":"2023-04-09T14:16:22.816336Z","shell.execute_reply":"2023-04-09T14:16:28.423885Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Accuracy:- 0.99836665391922\n","output_type":"stream"}]}]}